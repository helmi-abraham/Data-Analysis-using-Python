{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "745092c8-e50f-48ac-a1b5-dd4c47398f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programming for Data Analytics\n",
    "#Task 3\n",
    "# Helmi K Abraham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d8d6c58-abed-48df-af36-8ebc646711ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea68672e-e962-46ba-b349-c9e590c4f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = csv.reader(open('Downloads/HR_comma_sep.csv','r'),delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "154a671c-ef04-4e70-aff9-4faff8e781b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_csv.reader at 0x2c2a4aac1c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36ffebb4-794a-46e9-85f9-715292390ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting columns\n",
    "column = list(zip(*data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "057a35e3-5292-411d-9b63-3a1bc4d78244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7319c508-c16b-491b-ab88-ae4a7a774a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('satisfaction_level',\n",
       " '0.38',\n",
       " '0.8',\n",
       " '0.11',\n",
       " '0.72',\n",
       " '0.37',\n",
       " '0.41',\n",
       " '0.1',\n",
       " '0.92',\n",
       " '0.89',\n",
       " '0.42')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying First 10 elements of column 1\n",
    "column[0][0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2f655b0-ae25-4630-8bb0-29fd020c1c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Per Column:\n",
      "satisfaction_level: 0 missing values\n",
      "last_evaluation: 0 missing values\n",
      "number_project: 0 missing values\n",
      "average_montly_hours: 0 missing values\n",
      "time_spend_company: 0 missing values\n",
      "Work_accident: 0 missing values\n",
      "left: 0 missing values\n",
      "promotion_last_5years: 0 missing values\n",
      "Department: 0 missing values\n",
      "salary: 0 missing values\n"
     ]
    }
   ],
   "source": [
    "# Function to find missing values in the dataset\n",
    "def missing_values(file_path):\n",
    "    missing_values = {}\n",
    "    \n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        headers = next(csv_reader)  # Read the header row\n",
    "        \n",
    "        # Initialize a dictionary to track missing values for each column\n",
    "        for header in headers:\n",
    "            missing_values[header] = 0\n",
    "        \n",
    "        # Check for missing values in each row\n",
    "        for row in csv_reader:\n",
    "            for i, value in enumerate(row):\n",
    "                if value.strip() == \"\" or value.strip().lower() in [\"na\", \"null\"]:  # Check for empty or placeholders\n",
    "                    missing_values[headers[i]] += 1\n",
    "                    \n",
    "    return missing_values\n",
    "\n",
    "\n",
    "\n",
    "file_path = 'Downloads/HR_comma_sep.csv'\n",
    "\n",
    "# Find missing values\n",
    "missing_values = missing_values(file_path)\n",
    "\n",
    "# Display results\n",
    "print(\"Missing Values Per Column:\")\n",
    "for column, count in missing_values.items():\n",
    "    print(f\"{column}: {count} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90f6cb44-dbdd-4766-9b0b-daccd9e25e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics for Column: satisfaction_level\n",
      "  Mean: 0.6128335222348156\n",
      "  Median: 0.64\n",
      "  Mode: 0.1\n",
      "  Variance: 0.061813079225616394\n",
      "  Standard Deviation: 0.2486223626820733\n",
      "  Min: 0.09\n",
      "  Max: 1.0\n",
      "  Range: 0.91\n",
      "Interquartile Range (IQR): 0.37999999999999995\n",
      "\n",
      "Summary Statistics for Column: last_evaluation\n",
      "  Mean: 0.7161017401160077\n",
      "  Median: 0.72\n",
      "  Mode: 0.55\n",
      "  Variance: 0.029296911043708445\n",
      "  Standard Deviation: 0.1711634045107436\n",
      "  Min: 0.36\n",
      "  Max: 1.0\n",
      "  Range: 0.64\n",
      "Interquartile Range (IQR): 0.30999999999999994\n",
      "\n",
      "Summary Statistics for Column: number_project\n",
      "  Mean: 3.80305353690246\n",
      "  Median: 4.0\n",
      "  Mode: 4.0\n",
      "  Variance: 1.5191826220421272\n",
      "  Standard Deviation: 1.2325512654823438\n",
      "  Min: 2.0\n",
      "  Max: 7.0\n",
      "  Range: 5.0\n",
      "Interquartile Range (IQR): 2.0\n",
      "\n",
      "Summary Statistics for Column: average_montly_hours\n",
      "  Mean: 201.0503366891126\n",
      "  Median: 200.0\n",
      "  Mode: 135.0\n",
      "  Variance: 2494.146876178393\n",
      "  Standard Deviation: 49.94143446256218\n",
      "  Min: 96.0\n",
      "  Max: 310.0\n",
      "  Range: 214.0\n",
      "Interquartile Range (IQR): 89.0\n",
      "\n",
      "Summary Statistics for Column: time_spend_company\n",
      "  Mean: 3.498233215547703\n",
      "  Median: 3.0\n",
      "  Mode: 3.0\n",
      "  Variance: 2.131855669058738\n",
      "  Standard Deviation: 1.4600875552715111\n",
      "  Min: 2.0\n",
      "  Max: 10.0\n",
      "  Range: 8.0\n",
      "Interquartile Range (IQR): 1.0\n",
      "\n",
      "Summary Statistics for Column: Work_accident\n",
      "  Mean: 0.1446096406427095\n",
      "  Median: 0.0\n",
      "  Mode: 0.0\n",
      "  Variance: 0.12369769247589593\n",
      "  Standard Deviation: 0.3517068274513532\n",
      "  Min: 0.0\n",
      "  Max: 1.0\n",
      "  Range: 1.0\n",
      "Interquartile Range (IQR): 0.0\n",
      "\n",
      "Summary Statistics for Column: left\n",
      "  Mean: 0.2380825388359224\n",
      "  Median: 0.0\n",
      "  Mode: 0.0\n",
      "  Variance: 0.1813992435373639\n",
      "  Standard Deviation: 0.42590990072709495\n",
      "  Min: 0.0\n",
      "  Max: 1.0\n",
      "  Range: 1.0\n",
      "Interquartile Range (IQR): 0.0\n",
      "\n",
      "Summary Statistics for Column: promotion_last_5years\n",
      "  Mean: 0.021268084538969265\n",
      "  Median: 0.0\n",
      "  Mode: 0.0\n",
      "  Variance: 0.02081575311901252\n",
      "  Standard Deviation: 0.14427665479561314\n",
      "  Min: 0.0\n",
      "  Max: 1.0\n",
      "  Range: 1.0\n",
      "Interquartile Range (IQR): 0.0\n",
      "\n",
      "Summary Statistics for Column: Department\n",
      "  Frequency Distribution: {'sales': 0.2760184012267484, 'accounting': 0.05113674244949663, 'hr': 0.04926995133008867, 'technical': 0.1813454230282019, 'support': 0.14860990732715515, 'management': 0.04200280018667911, 'IT': 0.08180545369691312, 'product_mng': 0.0601373424894993, 'marketing': 0.057203813587572504, 'RandD': 0.052470164677645176}\n",
      "\n",
      "Summary Statistics for Column: salary\n",
      "  Frequency Distribution: {'low': 0.48776585105673714, 'medium': 0.4297619841322755, 'high': 0.0824721648109874}\n"
     ]
    }
   ],
   "source": [
    "# Calculating Summary Statisc\n",
    "# Mean\n",
    "def calculate_mean(data):\n",
    "    return sum(data) / len(data) if data else 0\n",
    "\n",
    "# Median\n",
    "def calculate_median(data):\n",
    "    data.sort()\n",
    "    n = len(data)\n",
    "    if n % 2 == 0:\n",
    "        return (data[n // 2 - 1] + data[n // 2]) / 2\n",
    "    else:\n",
    "        return data[n // 2]\n",
    "\n",
    "# Mode\n",
    "def calculate_mode(data):\n",
    "    counter = Counter(data)\n",
    "    return counter.most_common(1)[0][0]\n",
    "\n",
    "# Standard deviation and Variance\n",
    "def calculate_variance_std(data):\n",
    "    mean = calculate_mean(data)\n",
    "    variance = sum((x - mean) ** 2 for x in data) / len(data)\n",
    "    std_dev = sqrt(variance)\n",
    "    return variance, std_dev\n",
    "\n",
    "# Min and Max\n",
    "def calculate_min_max(data):\n",
    "    return min(data), max(data)\n",
    "    \n",
    "# Function to calculate range\n",
    "def calculate_range(data):\n",
    "    return max(data) - min(data)\n",
    "    \n",
    "# Function to calculate the interquartile range (IQR)\n",
    "def calculate_iqr(data):\n",
    "    sorted_data = sorted(data)\n",
    "    n = len(sorted_data)\n",
    "    Q1 = sorted_data[n // 4]\n",
    "    Q3 = sorted_data[3 * n // 4]\n",
    "    return Q3 - Q1\n",
    "\n",
    "\n",
    "# Processing categorical columns\n",
    "def process_categorical(data):\n",
    "    counter = Counter(data)\n",
    "    total = sum(counter.values())\n",
    "    relative_freq = {k: v / total for k, v in counter.items()}\n",
    "    return relative_freq\n",
    "\n",
    "# Main function to calculate summary statistics\n",
    "def summary_statistics(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        data = {col: [] for col in reader.fieldnames}\n",
    "        \n",
    "        # Read the dataset into a dictionary of lists\n",
    "        for row in reader:\n",
    "            for col, value in row.items():\n",
    "                if value.isdigit() or is_float(value):   # Check for numerical data\n",
    "                    data[col].append(float(value))\n",
    "                else:                                    # Treat as categorical/boolean\n",
    "                    data[col].append(value)\n",
    "        \n",
    "        # Calculate statistics for each column\n",
    "        for col, values in data.items():\n",
    "            print(f\"\\nSummary Statistics for Column: {col}\")\n",
    "            \n",
    "            if isinstance(values[0], (int, float)):      # Numerical columns\n",
    "                mean = calculate_mean(values)\n",
    "                median = calculate_median(values)\n",
    "                mode = calculate_mode(values)\n",
    "                variance, std_dev = calculate_variance_std(values)\n",
    "                min_val, max_val = calculate_min_max(values)\n",
    "                range = calculate_range(values)\n",
    "                iqr = calculate_iqr(values)\n",
    "                print(f\"  Mean: {mean}\")\n",
    "                print(f\"  Median: {median}\")\n",
    "                print(f\"  Mode: {mode}\")\n",
    "                print(f\"  Variance: {variance}\")\n",
    "                print(f\"  Standard Deviation: {std_dev}\")\n",
    "                print(f\"  Min: {min_val}\")\n",
    "                print(f\"  Max: {max_val}\")\n",
    "                print(f\"  Range: {range}\")\n",
    "                print(f\"Interquartile Range (IQR): {iqr}\")\n",
    "            \n",
    "            else:                                         # Categorical/boolean columns\n",
    "                freq_dist = process_categorical(values)\n",
    "                print(f\"  Frequency Distribution: {freq_dist}\")\n",
    "\n",
    "#Function to check if a value is a float\n",
    "def is_float(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Dataset\n",
    "summary_statistics('Downloads/HR_comma_sep.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c58f3961-673e-4ff9-888f-77c59e92b601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time Using Pure Python: 0.1277 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to calculate execution time\n",
    "def measure_execution_time(filename, pure_python_func):\n",
    "    start_time = time.time()\n",
    "    pure_python_func(filename)\n",
    "    duration = time.time() - start_time\n",
    "    return duration\n",
    "\n",
    "# Timing for finding summary statistics using pure Python\n",
    "def summary_statistics(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        data = {col: [] for col in reader.fieldnames}\n",
    "        \n",
    "        # Read the dataset into a dictionary of lists\n",
    "        for row in reader:\n",
    "            for col, value in row.items():\n",
    "                if value.isdigit() or is_float(value):  # Check for numerical data\n",
    "                    data[col].append(float(value))\n",
    "                else:                                   # Treat as categorical/boolean\n",
    "                    data[col].append(value)\n",
    "        \n",
    "        # Perform the computations\n",
    "        for col, values in data.items():\n",
    "            if isinstance(values[0], (int, float)):     # Numerical columns\n",
    "                calculate_mean(values)\n",
    "                calculate_median(values)\n",
    "                calculate_mode(values)\n",
    "                calculate_variance_std(values)\n",
    "                calculate_min_max(values)\n",
    "                calculate_range(values)\n",
    "                calculate_iqr(values)\n",
    "            else:                                       # Categorical columns\n",
    "                process_categorical(values)\n",
    "\n",
    "# Helper function to check if a value is a float\n",
    "def is_float(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Dataset\n",
    "filename = 'Downloads/HR_comma_sep.csv'\n",
    "\n",
    "# Measure execution time\n",
    "pure_python_time = measure_execution_time(filename, summary_statistics)\n",
    "print(f\"Execution Time Using Pure Python: {pure_python_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793f29b-e1c3-4d68-af9b-8876c4fc2885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
